{"cells":[{"cell_type":"markdown","metadata":{"id":"YSD4QWIRqNiW"},"source":["# Comprehensive Student Data Analysis with PySpark"]},{"cell_type":"markdown","metadata":{"id":"_WJDPO1WqQeJ"},"source":["## Objective"]},{"cell_type":"markdown","metadata":{"id":"WBTofZ06qS4d"},"source":["Leverage PySpark to perform a thorough analysis of student performance data. This exercise covers data loading and manipulation using RDDs and DataFrames, and it culminates in building and evaluating a logistic regression model to predict student success.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fMJPgi9-qT4x"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"2Cw1gpIoqWWJ"},"source":["**student_data.csv** includes:\n","\n","- age: Age of the student\n","- study_time: Weekly study hours\n","- failures: Number of past class failures\n","- passed: Course outcome (1: passed, 0: failed)"]},{"cell_type":"markdown","metadata":{"id":"OgMXfD6Vq5Kc"},"source":["## Set Up"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Z2M9-B0Wq-WP"},"outputs":[],"source":["# !pip install pyspark"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"RY0Ah382rAgy"},"outputs":[],"source":["import pyspark"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"PgeLaNopq6Z3"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/04/10 15:40:40 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n","from pyspark.ml import Pipeline\n","\n","spark = SparkSession.builder.appName(\"Student Data Analysis\").getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"Zojffl7Yqa1s"},"source":["## Tasks"]},{"cell_type":"markdown","metadata":{"id":"aAwqdwOXqcSK"},"source":["### Task 1: Resilient Distributed Dataset (RDD) Operations"]},{"cell_type":"markdown","metadata":{"id":"01q_KVuQqfG6"},"source":["1. Load student_data.csv into an RDD and remove the header."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"NkXQt8WarHtu"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/04/10 15:40:40 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["# YOUR CODE HERE\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .appName(\"Read CSV and Remove Header\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["student_data_rdd = spark.sparkContext.textFile(\"student_data.csv\")"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["header = student_data_rdd.first()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["data_without_header = student_data_rdd.filter(lambda row: row != header)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["['22,8,0,1',\n"," '19,7,2,0',\n"," '23,8,1,1',\n"," '20,6,2,0',\n"," '22,9,0,1',\n"," '18,5,3,0',\n"," '22,3,3,0',\n"," '23,3,1,0',\n"," '20,1,0,0',\n"," '19,8,1,1']"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["data_without_header.take(10)"]},{"cell_type":"markdown","metadata":{"id":"NwX_vDqsqh03"},"source":["2. Filter to include only students older than 20 years."]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435,"status":"ok","timestamp":1712160262244,"user":{"displayName":"Tien Dinh","userId":"09967600448114579438"},"user_tz":-420},"id":"YOSZHiosrfT4","outputId":"d03d84df-91a8-424c-f0d8-a506110c249e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]}],"source":["# YOUR CODE HERE\n","students_over_20 = data_without_header.filter(lambda row: int(row.split(',')[1]) > 20)\n","# View a sample of the filtered data (optional)\n","data_sample = students_over_20.take(10)\n","print(data_sample)"]},{"cell_type":"markdown","metadata":{"id":"Tvd2yv54qi3B"},"source":["3. Count students older than 20 with past failures.\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":853,"status":"ok","timestamp":1712160263096,"user":{"displayName":"Tien Dinh","userId":"09967600448114579438"},"user_tz":-420},"id":"tSe2gkaprjEV","outputId":"21eeca94-0450-4982-b144-384c5a97f4aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of students older than 20 with past failures: 0\n"]}],"source":["# YOUR CODE HERE\n","failing_students_over_20 = data_without_header.filter(lambda row: \n","                                                    int(row.split(',')[1]) > 20 and \n","                                                    row.split(',')[3] == \"True\")  # Adjust index for \"HasFailed\"\n","\n","# Count the failing students\n","student_count = failing_students_over_20.count()\n","\n","# Print the count\n","print(f\"Number of students older than 20 with past failures: {student_count}\")"]},{"cell_type":"markdown","metadata":{"id":"HwBhtf0ZqmmH"},"source":["### Task 2: DataFrame Operations"]},{"cell_type":"markdown","metadata":{"id":"I_10Z42dqoqa"},"source":["1. Load student_data.csv into a DataFrame."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"uYdugcGPrwMN"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/04/10 15:40:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]},{"name":"stdout","output_type":"stream","text":["+---+----------+--------+------+\n","|age|study_time|failures|passed|\n","+---+----------+--------+------+\n","| 22|         8|       0|     1|\n","| 19|         7|       2|     0|\n","| 23|         8|       1|     1|\n","| 20|         6|       2|     0|\n","| 22|         9|       0|     1|\n","| 18|         5|       3|     0|\n","| 22|         3|       3|     0|\n","| 23|         3|       1|     0|\n","| 20|         1|       0|     0|\n","| 19|         8|       1|     1|\n","| 23|         2|       0|     0|\n","| 23|         3|       2|     0|\n","| 18|         8|       1|     1|\n","| 21|         8|       3|     0|\n","| 20|         4|       2|     0|\n","| 17|         4|       2|     0|\n","| 23|         5|       1|     1|\n","| 21|         6|       3|     0|\n","| 17|         5|       2|     0|\n","| 20|         7|       0|     1|\n","+---+----------+--------+------+\n","only showing top 20 rows\n","\n"]}],"source":["# YOUR CODE HERE\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","    .appName(\"Load CSV to DataFrame\") \\\n","    .getOrCreate()\n","\n","# Read the CSV file into a DataFrame with inference of schema\n","df = spark.read.option(\"header\", \"true\").csv(\"student_data.csv\")\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"IrNU7Mffqphn"},"source":["2. Explore the data by displaying the schema and the first five rows."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1712160264286,"user":{"displayName":"Tien Dinh","userId":"09967600448114579438"},"user_tz":-420},"id":"2FjXBAgzr0OT","outputId":"ec1f6427-3ead-4d5d-9f95-125cef4e9db5"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- age: string (nullable = true)\n"," |-- study_time: string (nullable = true)\n"," |-- failures: string (nullable = true)\n"," |-- passed: string (nullable = true)\n","\n","+---+----------+--------+------+\n","|age|study_time|failures|passed|\n","+---+----------+--------+------+\n","| 22|         8|       0|     1|\n","| 19|         7|       2|     0|\n","| 23|         8|       1|     1|\n","| 20|         6|       2|     0|\n","| 22|         9|       0|     1|\n","| 18|         5|       3|     0|\n","| 22|         3|       3|     0|\n","| 23|         3|       1|     0|\n","| 20|         1|       0|     0|\n","| 19|         8|       1|     1|\n","| 23|         2|       0|     0|\n","| 23|         3|       2|     0|\n","| 18|         8|       1|     1|\n","| 21|         8|       3|     0|\n","| 20|         4|       2|     0|\n","| 17|         4|       2|     0|\n","| 23|         5|       1|     1|\n","| 21|         6|       3|     0|\n","| 17|         5|       2|     0|\n","| 20|         7|       0|     1|\n","+---+----------+--------+------+\n","only showing top 20 rows\n","\n"]}],"source":["# YOUR CODE HERE\n","df.printSchema()\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"UPgNK3GhqsWn"},"source":["3. Add a new column study_time_hours converting study time from hours to minutes."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"KkNO3_cfr2qC"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+--------+------+----------------+\n","|age|study_time|failures|passed|study_time_hours|\n","+---+----------+--------+------+----------------+\n","| 22|         8|       0|     1|           480.0|\n","| 19|         7|       2|     0|           420.0|\n","| 23|         8|       1|     1|           480.0|\n","| 20|         6|       2|     0|           360.0|\n","| 22|         9|       0|     1|           540.0|\n","| 18|         5|       3|     0|           300.0|\n","| 22|         3|       3|     0|           180.0|\n","| 23|         3|       1|     0|           180.0|\n","| 20|         1|       0|     0|            60.0|\n","| 19|         8|       1|     1|           480.0|\n","| 23|         2|       0|     0|           120.0|\n","| 23|         3|       2|     0|           180.0|\n","| 18|         8|       1|     1|           480.0|\n","| 21|         8|       3|     0|           480.0|\n","| 20|         4|       2|     0|           240.0|\n","| 17|         4|       2|     0|           240.0|\n","| 23|         5|       1|     1|           300.0|\n","| 21|         6|       3|     0|           360.0|\n","| 17|         5|       2|     0|           300.0|\n","| 20|         7|       0|     1|           420.0|\n","+---+----------+--------+------+----------------+\n","only showing top 20 rows\n","\n"]}],"source":["# YOUR CODE HERE\n","df = df.withColumn(\"study_time_hours\", col(\"study_time\") * 60)\n","df.show()"]},{"cell_type":"markdown","metadata":{"id":"HwCI19seqt51"},"source":["4. Calculate the average age of students grouped by their pass/fail status."]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1211,"status":"ok","timestamp":1712160265496,"user":{"displayName":"Tien Dinh","userId":"09967600448114579438"},"user_tz":-420},"id":"Mdt52dTrr4XJ","outputId":"5a579504-b522-482c-dd02-74102a14800c"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+------------------+\n","|passed|       average_age|\n","+------+------------------+\n","|     0|19.845565749235472|\n","|     1|19.997109826589597|\n","+------+------------------+\n","\n"]}],"source":["# YOUR CODE HERE\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, avg\n","\n","average_age_df = df.groupBy(\"passed\").agg(avg(df[\"age\"]).alias(\"average_age\"))\n","average_age_df.show()"]},{"cell_type":"markdown","metadata":{"id":"U-icLGf3qu30"},"source":["### Task 3: Logistic Regression Model"]},{"cell_type":"markdown","metadata":{"id":"3fLJRW_9qyUJ"},"source":["1. Prepare the data by vectorizing features and splitting into training and test datasets.\n"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"wITH4ocasVEv"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/04/10 15:40:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["# YOUR CODE HERE\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.tuning import TrainValidationSplit\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","# Khởi tạo phiên Spark\n","spark = SparkSession.builder \\\n","    .appName(\"Data Preparation\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- age: integer (nullable = true)\n"," |-- study_time: integer (nullable = true)\n"," |-- failures: integer (nullable = true)\n"," |-- passed: integer (nullable = true)\n","\n"]}],"source":["data_model = spark.read.csv(\"student_data.csv\", header=True, inferSchema=True)\n","data_model.printSchema()"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# vector hóa các cột dữ liệu cần thiết\n","feature_cols = data_model.columns[:-1]\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","data_model = assembler.transform(data_model)\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+--------+------+--------------+\n","|age|study_time|failures|passed|      features|\n","+---+----------+--------+------+--------------+\n","| 22|         8|       0|     1|[22.0,8.0,0.0]|\n","| 19|         7|       2|     0|[19.0,7.0,2.0]|\n","| 23|         8|       1|     1|[23.0,8.0,1.0]|\n","| 20|         6|       2|     0|[20.0,6.0,2.0]|\n","| 22|         9|       0|     1|[22.0,9.0,0.0]|\n","+---+----------+--------+------+--------------+\n","only showing top 5 rows\n","\n"]}],"source":["data_model.show(5)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["#chia dữ liệu ra thành tệp train và tệp test\n","(train_data, test_data) = data_model.randomSplit([0.8, 0.2], seed=42)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Số lượng dữ liệu huấn luyện: 838\n","Số lượng dữ liệu kiểm tra: 162\n","+---+----------+--------+------+--------------+\n","|age|study_time|failures|passed|      features|\n","+---+----------+--------+------+--------------+\n","| 16|         1|       0|     0|[16.0,1.0,0.0]|\n","| 16|         1|       0|     0|[16.0,1.0,0.0]|\n","| 16|         1|       0|     0|[16.0,1.0,0.0]|\n","| 16|         1|       0|     0|[16.0,1.0,0.0]|\n","| 16|         1|       0|     0|[16.0,1.0,0.0]|\n","+---+----------+--------+------+--------------+\n","only showing top 5 rows\n","\n"]}],"source":["print(\"Số lượng dữ liệu huấn luyện:\", train_data.count())\n","print(\"Số lượng dữ liệu kiểm tra:\", test_data.count())\n","train_data.show(5)"]},{"cell_type":"markdown","metadata":{"id":"F9G8omVAqz-q"},"source":["2. Build and train a logistic regression model."]},{"cell_type":"code","execution_count":54,"metadata":{"id":"kyWaaMY5sZf1"},"outputs":[],"source":["# YOUR CODE HERE\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["lr = LogisticRegression(featuresCol='features', labelCol='passed')"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/04/10 15:47:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n","24/04/10 15:47:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"]}],"source":["lr_model = lr.fit(train_data)"]},{"cell_type":"markdown","metadata":{"id":"ayGJ3QWuq1qO"},"source":["3. Evaluate the model using accuracy, precision, recall, F1 score, and the area under the ROC curve.\n"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1207,"status":"ok","timestamp":1712160272791,"user":{"displayName":"Tien Dinh","userId":"09967600448114579438"},"user_tz":-420},"id":"_rv7Of4osbU-","outputId":"18abf47d-c8d5-424e-cb55-da2097887f24"},"outputs":[],"source":["# YOUR CODE HERE\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n","from pyspark.mllib.evaluation import MulticlassMetrics"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["predictions = lr_model.transform(test_data)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy: 0.8888888888888888\n"]}],"source":["# độ chính xác\n","accuracy_evaluator = MulticlassClassificationEvaluator(labelCol='passed', predictionCol='prediction', metricName='accuracy')\n","accuracy = accuracy_evaluator.evaluate(predictions)\n","print(\"accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.8901141743247007\n"]}],"source":["# Đánh giá độ chính xác có trọng số\n","precision_evaluator = MulticlassClassificationEvaluator(labelCol='passed', predictionCol='prediction', metricName='weightedPrecision')\n","precision = precision_evaluator.evaluate(predictions)\n","print(\"precision:\", precision)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["recall: 0.8888888888888888\n"]}],"source":["# đánh giá recall\n","recall_evaluator = MulticlassClassificationEvaluator(labelCol='passed', predictionCol='prediction', metricName='weightedRecall')\n","recall = recall_evaluator.evaluate(predictions)\n","print(\"recall:\", recall)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["F1_score: 0.8893568433662774\n"]}],"source":["# Đánh giá F1 score\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol='passed', predictionCol='prediction', metricName='f1')\n","f1_score = f1_evaluator.evaluate(predictions)\n","print(\"F1_score:\", f1_score)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the area under the ROC curve: 0.8805437553101104\n"]}],"source":["# the area under the ROC curve\n","binary_evaluator = BinaryClassificationEvaluator(labelCol='passed', rawPredictionCol='prediction')\n","roc_auc = binary_evaluator.evaluate(predictions)\n","print(\"the area under the ROC curve:\", roc_auc)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOa5Xr03nL0wbjgCdMfJBm9","provenance":[{"file_id":"1hAJWBiM1hu0XVSAQKErpDbZEv72qOc9m","timestamp":1712160336862}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
